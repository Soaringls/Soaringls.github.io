<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  
  <link rel="canonical" href="https://example.com/M%26L/slam_basic/">
  <link rel="shortcut icon" href="../../img/favicon.ico">
  <title>Slam basic - MkLorum</title>
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lato:400,700|Roboto+Slab:400,700|Inconsolata:400,700" />

  <link rel="stylesheet" href="../../css/theme.css" />
  <link rel="stylesheet" href="../../css/theme_extra.css" />
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/styles/github.min.css" />
  
  <script>
    // Current page data
    var mkdocs_page_name = "Slam basic";
    var mkdocs_page_input_path = "M&L/slam_basic.md";
    var mkdocs_page_url = "/M%26L/slam_basic/";
  </script>
  
  <script src="../../js/jquery-2.1.1.min.js" defer></script>
  <script src="../../js/modernizr-2.8.3.min.js" defer></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/highlight.min.js"></script>
  <script>hljs.initHighlightingOnLoad();</script> 
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
        <a href="../.." class="icon icon-home"> MkLorum</a>
        <div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../../search.html" method="get">
      <input type="text" name="q" placeholder="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
                <ul>
                    <li class="toctree-l1"><a class="reference internal" href="../..">Home</a>
                    </li>
                </ul>
                <ul>
                    <li class="toctree-l1"><a class="" href="../../about.md">About</a>
                    </li>
                </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="../..">MkLorum</a>
      </nav>

      
      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../..">Docs</a> &raquo;</li>
    
      
    
    <li>Slam basic</li>
    <li class="wy-breadcrumbs-aside">
      
    </li>
  </ul>
  
  <hr/>
</div>

          <div role="main">
            <div class="section">
              
                <h3 id="_1">三维刚体运动</h3>
<p><code>四元数的共轭conjugate 即为其自身的逆</code>
$$
T = 
\begin{bmatrix}
  R &amp; t \\
  0^T &amp; 1<br />
\end{bmatrix} \quad R^T = R^{-1} \qquad \rightarrow \qquad</p>
<p>T^{-1} =  <br />
\begin{bmatrix}     <br />
   R^T &amp; -R^Tt \\     <br />
   0^T &amp; 1  <br />
\end{bmatrix}
$$</p>
<h3 id="_2">反对称矩阵</h3>
<p>$$
  \begin{aligned}
  \mathbf{\overrightarrow{a}}\times\mathbf{\overrightarrow{b}} &amp;= 
     \begin{bmatrix}
     \mathbf{i} &amp; \mathbf{j}&amp; \mathbf{k}\\
     a_1      &amp; a_2     &amp;a_3\\
     b_1      &amp; b_2     &amp;b_3
     \end{bmatrix} \\ 
     &amp;=\begin{bmatrix}
         a_2b_3 - a_3b_2 \\
         a_3b_1 - a_1b_3 \\
         a_1b_2 - a_2b_1
     \end{bmatrix}\\
     &amp;=
     \begin{bmatrix}     <br />
     0 &amp; -a_3 &amp; a_2  \\      <br />
     a_3 &amp; 0 &amp; -a_1 \\
     -a_2 &amp; a_1 &amp; 0     <br />
     \end{bmatrix} .\text{即为a的反对称矩阵} \\ &amp;=\hat{\mathbf{a}}\mathbf{k}
  \end{aligned} \tag{4}
  $$</p>
<h3 id="camera">Camera</h3>
<ul>
<li>像素坐标<code>(u, v)</code>和相机坐标<code>(X, Y, Z)</code>的转换推导
  $$
  \begin{bmatrix}
      u \\
      v \\
      1
  \end{bmatrix} = \frac{1}{Z}
  \begin{bmatrix}
      f_x &amp; 0 &amp; cx \\
      0 &amp; f_y &amp; cy \\
      0 &amp; 0 &amp; 1
  \end{bmatrix}
  \begin{bmatrix}
      X \\ Y \\ 1
  \end{bmatrix} = \frac{1}{Z} \cdot KP_c 
  = \frac{1}{Z} \cdot KT  P_w 
  $$
  K为相机内参矩阵， $T$为路标点$P_w$对应的外参(用于先将路标点由世界系转到<strong>相机系</strong>,即$P_c = RP_w +t$),
  归一化相机坐标: $P_c = (\frac{X}{Z}, \frac{Y}{Z},1)$, 像素坐标:$P_{uv} = KP_c$</li>
</ul>
<p>$$
\begin{cases} 
  u = \alpha X^\prime +cx \\ 
  v = \beta Y^\prime + cy \quad cx和cy的基本单位:pixel
\end{cases}  \rightarrow</p>
<p>\begin{cases}
  u = \alpha \cdot f \cdot \frac{X}{Z} + cx \\
  v = \beta \cdot f \cdot \frac{Y}{Z} + cy \quad \alpha和\beta的基本单位:pixels/m
\end{cases}  \rightarrow </p>
<p>\begin{cases}
  u = f_x \cdot \frac{X}{Z} +cx \\
  v = f_y \cdot \frac{Y}{Z} +cy
\end{cases}
$$
- 双目
  $$
  Z = \frac{fb}{d} \qquad 视差d越小 \to Z越大,即测距越远，同理基线b越大也是如此
  $$</p>
<h3 id="_3">视觉里程计</h3>
<ul>
<li>2D-2D对极几何(计算求解: 旋转R 和 平移t)<br>
  $$
    x^T_2 \hat{t} R x_1 = 0 \qquad x_2和x_1为相机归一化坐标 \ 本质矩阵 E =\hat{t} R  \\
    P^T_2 K^{-T} \hat{t} R K^{-1} P_1 = 0 \qquad 基础矩阵 F = K^{-T} \hat{t} R K^{-1}
  $$
  本质矩阵$E$在不同尺度下等价,因此与尺度无关。 特征点共面或相机纯旋转时$E$的自由度下降,即退化,因此一般同时估计基础矩阵$F$和单应性矩阵$H$,选取重投影误差比较小的作为最终的运动估计矩阵。<br>
  <strong>单目slam初始化[旋转+平移]: 的2个image<code>must</code>有一定的平移量,而后的轨迹和地图都以此为单位</strong></li>
<li>三角化测量(计算求解: 路标点即地图点的空间位置)
  $$
  s_1 x_1  = s_2 R x_2 + t
  $$</li>
</ul>
<h3 id="_4">非线性最小二乘</h3>
<h4 id="_5">状态估计</h4>
<p>机器人状态估计中已知输入数据 $\mathcal{u}$ 和观测数据 $\mathcal{x}$ 的条件下, 未知状态 $x$ 的条件概率分布为: $P(x|z,u)$, 当没有测量运动的传感器时相当于估计$P(x|z)$ 的条件概率分布(若忽略时序关系则可理解为一个SFM问题)</p>
<blockquote>
<p>求最大后验 $\simeq$ 求最大似然估计 $\to$ 最小化负对数(最小二乘问题)
- <strong>利用贝叶斯法则</strong>
$$
P(x|z) = \frac{P(z|x)P(x)}{P(z)}  \propto P(z|x)P(x)
$$
$$
后验P(x|z) * 常数(evidence)P(z)= 似然(likelihood)P(z|x) * 先验P(x)
$$
- 最大化后验概率(Maximize a Posterior,MAP): 
$$
x^<em>_{MAP} = argmax P(x|z) = argmax P(z|x)P(x)
$$
- 一般还不知道机器人大概的位置，此时没有了</em><em>先验</em><em>
  所以求</em><em>最大化后验概率</em><em>相当于求 $x$ 的</em><em>最大似然估计</em><em>(Maximize Likelihood Estimation,MLE)
<code>似然:在现在的姿态下，可能产生什么样的观测数据</code>
<code>最大似然估计:什么样的状态下，最可能产生当前的观测数据</code>----&gt;等同于求最大后验
$$
x^</em><em>{MLE} = argmax P(z|x)<br />
$$
  - 对于观测模型 $z</em>{k,j} = h(y_j, x_k) + v_{k,j}$, 似然 $P(z|x) = N(h(y_j, x_k),Q_{k,j})$服从高斯分布,
  - 为最大化似 $x_k, y_j$, 然通常使用<strong>最小化负对数</strong>来求一个高斯分布的最大似然
    一般，对于一个任意的高斯分布 $x \sim N(\mu, \Sigma)$, 其概率密度函数$P(x) = \frac{1}{\sqrt{(2\pi)^N det(\Sigma)}}exp\left(-\frac{1}{2}(x - \mu)^T \Sigma^{-1} (x - \mu)\right)$
    取其负对数为: $-ln(P(x)) = \frac{1}{2}ln\left((2\pi)^N det(\Sigma)\right) + \frac{1}{2}(x - \mu)^T \Sigma^{-1} (x - \mu)$
  - <strong>负对数式</strong>的第一项与 $x$ 无关，直接略去, 则求状态的最大似然估计--&gt;最小化右侧的二次型项，代入SLAM观测模型，等同于求
    $x^* = argmin \left((z_{k,j} - h(x_k, y_i))^T Q^{-1}<em>{k,j} (z</em>{k,j} - h(x_k, y_i)) \right)$ 
    等价于求噪声项(即误差)的最小二乘</p>
</blockquote>
<h4 id="_6">最小二乘问题</h4>
<p>$$
\min\limits_{x}\frac{1}{2}|f(x)|^2
$$
未知自变量$x \isin \mathbb{R}^n$,$f$为一个任意的非线性函数,假设为$m$维:$f(x) \isin \mathbb{R}^m$。
- 解析形式求解: 令目标函数导数为零 $\frac{df}{d \mathbf{x}}=\mathbf{0}$,然后求解$\mathbf{x}$的最优解
- 优化求解:SLAM中的最小二乘问题导数形式比较复杂，使用迭代的方式从一个初始值出发，通过不断迭代更新当前的优化变量使目标函数下降
  1. 给定某个初始值$\mathbf{x}<em>0$
  2. 对于第$\mathcal{k}$次迭代，寻找一个增量$\Delta x_k$，使得$|f(x_k + \Delta x_k)|^2$达到极小值
  3. 若$\Delta x_k$足够小，则停止迭代
  4. 否则，令$x</em>{k+1} = x_k + \Delta x_k$
- 一阶和二阶梯度法
  将目标函数在 $x_k$ 附近泰勒展开
  $$
  f(x + \Delta)^2 = f(x)^2 + J(x)\Delta x + \frac{1}{2} \Delta x^T \mathbin{H} \Delta x
  $$
  $J$ 为 $f(x)^2$ 关于 $x$ 的导数(Jacobian矩阵)，而 $H$ 为二阶导数(Hessian矩阵)，保留泰勒展开的一阶或二阶项对应的求解方法则为一阶梯度或二阶梯度
  - 保留一阶梯度，增量方程为
    $$
    \Delta x^<em> = -J(x)
    $$
    直观意义简单，沿反向梯度方向前进即可，通常会计算该方向上的一个步长 $\lambda$, 以获得最快下降的方式---&gt;</em><em>最速下降法</em><em>(过于贪心,容易走锯齿路线，增加迭代次数)
  - 保留二阶梯度，增量方程为
    $$
    \Delta x^</em> = argminf(x)^2 +J(x) \Delta x + \frac{1}{2} \Delta x^T \mathbin{H} \Delta x
    $$
    该等式令关于 $\Delta x$ 的导数为零，得增量方程为: $H \Delta x = -J  $  <strong>牛顿法</strong>(需计算$H$矩阵，一般比较困难)
  - <strong>Gauss-Newton</strong>(最优化算法最简单的方法之一, 将$f(x)$进行一阶泰勒展开，而非目标函数$f(x)^2$)
    $$
    f(x + \Delta x) \approx f(x) + J(x)\Delta x
    $$
    该式$J(x)$为$f(x)$关于$x$的导数，得线性最小二乘问题为:
    $$
    \Delta x^<em><em>k = arg\min\limits</em>{\Delta x}\frac{1}{2} |f(x) + J(x)\Delta x|^2
    $$
    将最小二乘问题的目标函数$|f(x) + J(x)\Delta x|^2$对$\Delta x$求导并令导数为零得</em><em>增量方程(高斯牛顿方程GaussNewtonEquations或正规方程NormalEquations)</em><em>
    $$
    J(x)^T J(x) \Delta x = -J(x)f(x) \sim H \Delta x =g
    $$
    Gauss-Newton将$J^T J$作为牛顿法中二阶$Hessian$矩阵的近似，</em><em>求解增量方程是整个优化问题的核心</em>*
  - Gauss-Newton算法步骤
    1. 给定某个初始值$x_0$
    2. 对于第$\mathcal{k}$次迭代，求出当前的Jacobian矩阵$J(x_k)$和误差$f(x_k)$
    3. 求解增量方程:$H \Delta x =g$
    4. 若$\Delta x_k$足够小，则停止。否则，令$x_{k+1} = x_k + \Delta x_k$,然后返回步骤2</p>
              
            </div>
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
    
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
      
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
    
    
  </span>
</div>
    <script>var base_url = '../..';</script>
    <script src="../../js/theme_extra.js" defer></script>
    <script src="../../js/theme.js" defer></script>
      <script src="../../search/main.js" defer></script>
    <script defer>
        window.onload = function () {
            SphinxRtdTheme.Navigation.enable(true);
        };
    </script>

</body>
</html>
